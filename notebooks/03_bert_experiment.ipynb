{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efea1c0",
   "metadata": {},
   "source": [
    "# Transformer-based Sentiment Analysis (BERT)\n",
    "\n",
    "## Objectif\n",
    "- Introduire un modèle Transformer (BERT)\n",
    "- Tester une approche contextualisée du sentiment\n",
    "- Comparer qualitativement avec TF-IDF + SVM\n",
    "\n",
    "Ce notebook est proposé comme une ouverture vers l’état de l’art.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f10705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch datasets accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5715bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "371d8805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>rating_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothing special charge diamond member hilton d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice room experience hotel monaco seattle good...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay went seahawk game awesom...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text rating_sentiment\n",
       "0  nice hotel expensive parking got good deal sta...         positive\n",
       "1  nothing special charge diamond member hilton d...         negative\n",
       "2  nice room experience hotel monaco seattle good...          neutral\n",
       "3  unique great stay wonderful time hotel monaco ...         positive\n",
       "4  great stay great stay went seahawk game awesom...         positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/feedbacks_enriched.csv\")\n",
    "\n",
    "df = df[[\"clean_text\", \"rating_sentiment\"]]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c5ccc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"positive\": 2\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "df[\"label\"] = df[\"rating_sentiment\"].map(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29db705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d8334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "def tokenize_text(texts):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3555a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset PyTorch minimal\n",
    "class FeedbackDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenize_text(texts)\n",
    "        self.labels = torch.tensor(labels.tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "train_dataset = FeedbackDataset(train_df[\"clean_text\"], train_df[\"label\"])\n",
    "test_dataset = FeedbackDataset(test_df[\"clean_text\"], test_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01c8cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#bert model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9981955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_results\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_steps=10000,\n",
    "    save_total_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc03d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50\n",
      "Test size: 50\n"
     ]
    }
   ],
   "source": [
    "# Limit samples to avoid RAM issues\n",
    "n_samples = 50  # change to None for full dataset\n",
    "\n",
    "if n_samples is not None:\n",
    "    train_df_small = train_df.iloc[:n_samples].reset_index(drop=True)\n",
    "    test_df_small = test_df.iloc[:n_samples].reset_index(drop=True)\n",
    "else:\n",
    "    train_df_small = train_df\n",
    "    test_df_small = test_df\n",
    "\n",
    "print(\"Train size:\", len(train_df_small))\n",
    "print(\"Test size:\", len(test_df_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb63cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FeedbackDataset(\n",
    "    train_df_small[\"clean_text\"],\n",
    "    train_df_small[\"label\"]\n",
    ")\n",
    "\n",
    "test_dataset = FeedbackDataset(\n",
    "    test_df_small[\"clean_text\"],\n",
    "    test_df_small[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c6c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakkarouis/anaconda3/envs/nlp_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48514b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakkarouis/anaconda3/envs/nlp_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 01:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=0.8769009453909737, metrics={'train_runtime': 93.8784, 'train_samples_per_second': 1.065, 'train_steps_per_second': 0.149, 'total_flos': 6577835443200.0, 'train_loss': 0.8769009453909737, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakkarouis/anaconda3/envs/nlp_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab07c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "     neutral       0.00      0.00      0.00         9\n",
      "    positive       0.76      1.00      0.86        38\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.25      0.33      0.29        50\n",
      "weighted avg       0.58      0.76      0.66        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakkarouis/anaconda3/envs/nlp_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/sakkarouis/anaconda3/envs/nlp_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/sakkarouis/anaconda3/envs/nlp_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = test_df_small[\"label\"].values  # ✅ 50 labels\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=[\"negative\", \"neutral\", \"positive\"]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255711c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use ONLY the reduced test dataframe (50 samples)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_df_small = \u001b[43mtest_df_small\u001b[49m.copy()\n\u001b[32m      4\u001b[39m test_df_small[\u001b[33m\"\u001b[39m\u001b[33mbert_pred\u001b[39m\u001b[33m\"\u001b[39m] = [id2label[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_pred]\n\u001b[32m      6\u001b[39m test_df_small[[\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrating_sentiment\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbert_pred\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m ]].head(\u001b[32m10\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df_small' is not defined"
     ]
    }
   ],
   "source": [
    "# Use ONLY the reduced test dataframe (50 samples)\n",
    "test_df_small = test_df_small.copy()\n",
    "\n",
    "test_df_small[\"bert_pred\"] = [id2label[i] for i in y_pred]\n",
    "\n",
    "test_df_small[[\n",
    "    \"clean_text\",\n",
    "    \"rating_sentiment\",\n",
    "    \"bert_pred\"\n",
    "]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e81b4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Cette expérimentation montre que :\n",
    "- BERT permet de capturer le contexte sémantique des feedbacks\n",
    "- Les performances peuvent être comparables ou supérieures\n",
    "- Le coût computationnel est nettement plus élevé\n",
    "\n",
    "Dans le cadre de ce projet, BERT est présenté comme une ouverture\n",
    "vers l’état de l’art plutôt qu’une solution de production.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
